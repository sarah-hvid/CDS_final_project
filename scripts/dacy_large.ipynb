{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da_dacy_small_tft-0.0.0\n",
      "da_dacy_medium_tft-0.0.0\n",
      "da_dacy_large_tft-0.0.0\n",
      "da_dacy_small_trf-0.1.0\n",
      "da_dacy_medium_trf-0.1.0\n",
      "da_dacy_large_trf-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarah\\anaconda3\\lib\\site-packages\\spacy\\util.py:732: UserWarning: [W095] Model 'en_core_web_sm' (3.0.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.1.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import dacy\n",
    "for model in dacy.models():\n",
    "    print(model)\n",
    "    \n",
    "nlp = dacy.load(\"da_dacy_large_trf-0.1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Opfordret af Deres Velbaarenhed til at erklære om jeg vedgaaer eller nægter at være Fader til et af Pigen Else Sophie Jensdatter Birkedalen født Drengebarn, som i Daaben den 25de October sidstleden er kaldet Hans Jacob, maa jeg herved ærbødigst meddele, at jeg ikke, uagtet Pigens Samqvem ogsaa med andre Mandspersoner paa den vedkommende Tid, bestemt tør fralægge mig bemeldte Paternitet, da jeg desværre med hende har pleiet legemlig Omgang, hvortil hendes fristende Adfærd og samtidige Tjeneste med mig hos Apotheker Reimann i lige Grad gav Anledning.Jeg er nu i 20de Aar gl:, eier aldeles Intet, uden nogle tarvelige Klæder, Skoetøi og Linned og skal om kort Tid forlade Grimstad Apothek, ved hvilket jeg som Lærling og altsaa uden nogen anden Løn, end Kosthold og de ovennævnte Fornødenheder, har opholdt mig siden Sommeren 1843. Min endnu levende Fader, til hvem jeg nødsages for det Første at begive mig, er en af de mindre Handelsmænd i Skien og befinder sig i høist maadelige Kaar.Til Vitterlighed:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in doc.ents:\n",
    "   print(entity, \":\", entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = [(e.label_, e.text) for e in doc.ents]\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(os.getcwd(), \"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\data_ibsen_work\\\\txt\\\\brev_p\", \"BREV*.txt\"))\n",
    "\n",
    "text = []\n",
    "files = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    with open(file_path, encoding = 'utf8') as f_input:\n",
    "        t = f_input.read()\n",
    "        text.append(t)\n",
    "        file = (''.join([n for n in os.path.basename(file_path)]))\n",
    "        file = re.sub('\\.txt', '', file) \n",
    "        files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = text[2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = []\n",
    "\n",
    "for doc in nlp.pipe(text, disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    ents.append(([(e.label_, e.text) for e in doc.ents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ents = []\n",
    "   \n",
    "for doc in nlp.pipe(text, disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    in_list = []\n",
    "    for e in doc.ents:\n",
    "        if e.label_ == 'PER':\n",
    "            in_list.append((e.text))\n",
    "    ents.append(in_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_copy_new = ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_copy = ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {test_keys[i]: test_values[i] for i in range(len(test_keys))}\n",
    "res = {files[i]: text[i] for i in range(len(files))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = {'files': files, 'text': text, 'dacy_large': ents_copy_new}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(lists, orient = 'index')\n",
    "df = df.transpose()\n",
    "\n",
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Bachelor\\\\Ibsen\\\\ibsen_network\\\\\")\n",
    "df.to_csv(os.path.join(r'per_dacy_large_new.csv'), encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createList(n):\n",
    "    lst = []\n",
    "    for i in range(n+1):\n",
    "        lst.append(i)\n",
    "    return(lst)\n",
    "\n",
    "index = createList(2449)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dictionary\n",
    "myDict = {}\n",
    "  \n",
    "# Adding list as value\n",
    "myDict[\"key1\"] = [1, 2]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list\n",
    "lst = ['Geeks', 'For', 'Geeks']\n",
    "  \n",
    "# Adding this list as sublist in myDict\n",
    "myDict[\"key1\"].append(lst)\n",
    "  \n",
    "print(myDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for i in text:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = {}\n",
    "  \n",
    "# Adding list as value\n",
    "myDict[\"key1\"] = [1, 2]\n",
    "myDict[\"key2\"] = [\"Geeks\", \"For\", \"Geeks\"] \n",
    "  \n",
    "print(myDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
