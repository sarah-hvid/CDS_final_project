{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. script\n",
    "### This script cleans the dataframe and creates the adjacency matrix for the network\n",
    "#### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from ast import literal_eval\n",
    "from langdetect import detect\n",
    "from itertools import combinations\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from fuzzywuzzy.process import dedupe as fuzzy_dedupe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, we need to load the CSV file we just created. Replace with your directory within the quotations marks. It should point to the 'per_dacy_large.csv' file within the 'csv' folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Sarah\\\\Desktop\\\\Cultural_data_science\\\\Exam\\\\ibsen_network\\\\data\\\\csv\\\\per_dacy_large.csv', converters={'dacy_large': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>text</th>\n",
       "      <th>dacy_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREV_B1844-1871ht_18670308FH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREV_B1844-1871ht_B18260306NTB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREV_B1844-1871ht_B18440520PL</td>\n",
       "      <td>Du maa virkelig undskylde, at jeg først nu bes...</td>\n",
       "      <td>[Hedevall, Reimann, Reimann, Johan, Carl Aamod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREV_B1844-1871ht_B18441006HSte</td>\n",
       "      <td>Tilgiv at jeg ikke før har besvaret Dit Brev, ...</td>\n",
       "      <td>[Reimann, Mdm Reimann, Mdm R, Reimanns, Reiman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREV_B1844-1871ht_B18450801AWE</td>\n",
       "      <td>\\nJomfru M: Wahl hilses venskabeligst fra</td>\n",
       "      <td>[M: Wahl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Hjerteligste</td>\n",
       "      <td>\\nHjerteligste ønsker!Tør desværre ikke selv p...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Med_udtrykket</td>\n",
       "      <td>\\n\\nMed udtrykket af min sympati for komitéens...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Tallene</td>\n",
       "      <td>\\nTallene må utvilsomt være skrevne af mig sel...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>BREV_B1890-1905ht_BudatNN_Wenn_Sie</td>\n",
       "      <td>\\n\\n\\n Wenn Sie keine andere Verwendung für Ih...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>BREV_B1890-1905ht_BudatWA</td>\n",
       "      <td>\\nHjertelig velkommen når De vil! For resten v...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        files  \\\n",
       "0                BREV_B1844-1871ht_18670308FH   \n",
       "1              BREV_B1844-1871ht_B18260306NTB   \n",
       "2               BREV_B1844-1871ht_B18440520PL   \n",
       "3             BREV_B1844-1871ht_B18441006HSte   \n",
       "4              BREV_B1844-1871ht_B18450801AWE   \n",
       "...                                       ...   \n",
       "2444   BREV_B1890-1905ht_BudatNN_Hjerteligste   \n",
       "2445  BREV_B1890-1905ht_BudatNN_Med_udtrykket   \n",
       "2446        BREV_B1890-1905ht_BudatNN_Tallene   \n",
       "2447       BREV_B1890-1905ht_BudatNN_Wenn_Sie   \n",
       "2448                BREV_B1890-1905ht_BudatWA   \n",
       "\n",
       "                                                   text  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2     Du maa virkelig undskylde, at jeg først nu bes...   \n",
       "3     Tilgiv at jeg ikke før har besvaret Dit Brev, ...   \n",
       "4             \\nJomfru M: Wahl hilses venskabeligst fra   \n",
       "...                                                 ...   \n",
       "2444  \\nHjerteligste ønsker!Tør desværre ikke selv p...   \n",
       "2445  \\n\\nMed udtrykket af min sympati for komitéens...   \n",
       "2446  \\nTallene må utvilsomt være skrevne af mig sel...   \n",
       "2447  \\n\\n\\n Wenn Sie keine andere Verwendung für Ih...   \n",
       "2448  \\nHjertelig velkommen når De vil! For resten v...   \n",
       "\n",
       "                                             dacy_large  \n",
       "0                                                    []  \n",
       "1                                                    []  \n",
       "2     [Hedevall, Reimann, Reimann, Johan, Carl Aamod...  \n",
       "3     [Reimann, Mdm Reimann, Mdm R, Reimanns, Reiman...  \n",
       "4                                             [M: Wahl]  \n",
       "...                                                 ...  \n",
       "2444                                                 []  \n",
       "2445                                                 []  \n",
       "2446                                                 []  \n",
       "2447                                                 []  \n",
       "2448                                                 []  \n",
       "\n",
       "[2449 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to drop empty letters first. Then we need to remove the letters that were not written in Danish, as DaCy Large's predictions won't be good for these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [\"text\"], inplace=True)\n",
    "\n",
    "df['lang'] = df['text'].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['da', 'no', 'de', 'fr', 'en', 'it', 'nl', 'sv', 'vi', 'sw', 'af',\n",
       "       'hu', 'id'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[(df[\"lang\"] == 'da') | (df[\"lang\"] == 'no') | (df[\"lang\"] == 'sv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['dacy_large'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can create the adjacency matrix. The data needs to be in dictionary format for the functions to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text','dacy_large']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With the data in dictionary format, we can create a function that removes duplicate names in each letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupes(article):\n",
    "    contains_dupes = list(data[key]['dacy_large'])\n",
    "    deduped = fuzzy_dedupe(contains_dupes)\n",
    "    return deduped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: ': ']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '’']\n"
     ]
    }
   ],
   "source": [
    "for key in data:\n",
    "    if data[key]['text'] != '':\n",
    "        people = remove_dupes(str(data[key]['dacy_large']))\n",
    "        data[key]['people'] = people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Then we can create the adjacency matrix by making each entity a key and other entities in the same letter values of that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = {}\n",
    "\n",
    "for key in data:\n",
    "    people = data[key]['people']\n",
    "    \n",
    "    doc_ents = []\n",
    "    for person in people:\n",
    "            doc_ents.append(person)\n",
    "    \n",
    "    for ent in doc_ents:\n",
    "        try:\n",
    "            entities[ent].extend([doc for doc in doc_ents if doc != ent])\n",
    "        except:\n",
    "            entities[ent] = [doc for doc in doc_ents if doc != ent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, we can create a dataframe again from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([entities])\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = 'source'\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We also want each name on its own row, so we are exploding the target values. Additionally, we remove all names shsorter than 3 letters, as it wouldn't be possible to get the full name of the individual from so little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: 'target'})\n",
    "df = df.explode('target')\n",
    "\n",
    "df = df.dropna(subset = ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['target'].str.len() > 3) & (df['source'].str.len() > 3)\n",
    "df = df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hedevall</td>\n",
       "      <td>Reimann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hedevall</td>\n",
       "      <td>Johan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hedevall</td>\n",
       "      <td>Carl Aamodt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reimann</td>\n",
       "      <td>Hedevall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reimann</td>\n",
       "      <td>Johan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>Laura Fitinghoff</td>\n",
       "      <td>Henrik Ibsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>Wang</td>\n",
       "      <td>Peer Gynt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>Helga</td>\n",
       "      <td>Sigurds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>Hr. Skuespiller Garmann</td>\n",
       "      <td>Henrik Ibsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>Theaterchef Bjørnson</td>\n",
       "      <td>Henrik Ibsen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source        target\n",
       "0                    Hedevall       Reimann\n",
       "0                    Hedevall         Johan\n",
       "0                    Hedevall   Carl Aamodt\n",
       "1                     Reimann      Hedevall\n",
       "1                     Reimann         Johan\n",
       "...                       ...           ...\n",
       "1891         Laura Fitinghoff  Henrik Ibsen\n",
       "1893                     Wang     Peer Gynt\n",
       "1894                    Helga       Sigurds\n",
       "1895  Hr. Skuespiller Garmann  Henrik Ibsen\n",
       "1897     Theaterchef Bjørnson  Henrik Ibsen\n",
       "\n",
       "[17292 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The dataframe is now ready to be saved as a CSV file and imported to OpenRefine for the next preprocessing steps. The path should point to the CSV folder again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r\"C:\\\\Users\\\\Sarah\\\\Desktop\\\\Cultural_data_science\\\\Exam\\\\ibsen_network\\\\data\\\\csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(r'data_links.csv'), encoding = 'utf-8', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To reproduce the code within OpenRefine, the 'data_links.csv' file should be opened as a project. The TXT files named 'procedures_openrefine_target.txt' and 'procedures_openrefine_target.txt' should be applied to the dataframe in the project. Simply open them and copypaste the contents into the 'Redo'. Then, save the CSV file as 'OR_data_links.csv'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
